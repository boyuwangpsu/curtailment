{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import logging\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "from functools import partial\n",
    "from pathlib import Path\n",
    "from typing import List, Optional\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gluonts.dataset.common import TrainDatasets, load_datasets\n",
    "from gluonts.dataset.field_names import FieldName\n",
    "from gluonts.gluonts_tqdm import tqdm\n",
    "\n",
    "\n",
    "def _preprocess_retail_data(df, combination):\n",
    "    df[\"Country\"] = df[\"Country\"].astype(\"category\").cat.codes\n",
    "    df[\"StockCode\"] = df[\"StockCode\"].astype(\"category\").cat.codes\n",
    "    df = df.groupby([\"StockCode\", \"Country\", \"InvoiceDate\"]).agg(\n",
    "        {\"Quantity\": \"sum\", \"UnitPrice\": \"mean\"}\n",
    "    )\n",
    "    counts = df.reset_index().groupby(combination)[\"StockCode\"].count()\n",
    "    combinations_selected = counts[counts > 10].index\n",
    "    df = df.reset_index().set_index(combination)\n",
    "    df = df[df.index.isin(combinations_selected)]\n",
    "    max_date = df.InvoiceDate.max().replace(hour=0, minute=0, second=0)\n",
    "\n",
    "    def resample_ds(df):\n",
    "        df.InvoiceDate = pd.to_datetime(df.InvoiceDate, yearfirst=True)\n",
    "        df.rename(columns={\"InvoiceDate\": \"date\"}, inplace=True)\n",
    "        new_idx = pd.date_range(\n",
    "            df.date.min().replace(hour=0, minute=0, second=0),\n",
    "            max_date,\n",
    "            freq=\"1D\",\n",
    "            name=\"InvoiceDate\",\n",
    "        )\n",
    "        df.set_index(\"date\", inplace=True)\n",
    "        df = (\n",
    "            df.resample(\"1D\")\n",
    "            .agg({\"Quantity\": \"sum\", \"UnitPrice\": \"mean\"})\n",
    "            .reindex(new_idx)\n",
    "        )\n",
    "        df[\"Quantity\"] = df[\"Quantity\"].fillna(0)\n",
    "        df[\"UnitPrice\"] = df[\"UnitPrice\"].ffill().bfill()\n",
    "        return df\n",
    "\n",
    "    df = df.reset_index().groupby(combination).apply(resample_ds)\n",
    "    df.Quantity = df.Quantity.clip(lower=0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def generate_retail_dataset(dataset_path: Path, split: str = \"2011-11-24\"):\n",
    "    retail_dataset_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx\"\n",
    "    df = pd.read_excel(retail_dataset_url)\n",
    "    combination = [\"StockCode\", \"Country\"]\n",
    "    df = _preprocess_retail_data(df, combination)\n",
    "    # df.to_pickle(\"temp.pkl\")\n",
    "    # df = pd.read_pickle(\"temp.pkl\")\n",
    "    idx = pd.IndexSlice[:, :, :split]\n",
    "    train_df = df.loc[idx, :].reset_index()\n",
    "    idx = pd.IndexSlice[:, :, split:]\n",
    "    test_df = df.loc[idx, :].reset_index()\n",
    "    full_df = df.reset_index()\n",
    "    single_prediction_length = len(test_df[\"InvoiceDate\"].unique())\n",
    "    feat_static_cat = combination\n",
    "    # feat_dynamic_real = []\n",
    "    target = \"Quantity\"\n",
    "    date_col = \"InvoiceDate\"\n",
    "\n",
    "    os.makedirs(dataset_path, exist_ok=True)\n",
    "\n",
    "    uniq_combs = train_df[combination].drop_duplicates().apply(tuple, axis=1)\n",
    "    # dynamic_real_train_l = []\n",
    "    # dynamic_real_test_l = []\n",
    "    stat_cat_l = []\n",
    "    start_l = []\n",
    "    train_target_l = []\n",
    "    test_target_l = []\n",
    "    for stock_code, country in tqdm(uniq_combs):\n",
    "        df = train_df[\n",
    "            (train_df.StockCode == stock_code) & (train_df.Country == country)\n",
    "        ]\n",
    "        _df = full_df[(full_df.StockCode == stock_code) & (full_df.Country == country)]\n",
    "        train_ts = _df[target].values.ravel()\n",
    "        if (train_ts > 0).sum() > (single_prediction_length + 13):\n",
    "            # test_feat_dyn_array = _df.loc[:, feat_dynamic_real].values.T\n",
    "            # train_feat_dyn_array = test_feat_dyn_array[:, :-single_prediction_length]\n",
    "\n",
    "            test_ts = train_ts.copy()\n",
    "            train_ts = train_ts[:-single_prediction_length]\n",
    "\n",
    "            # dynamic_real_train_l.append(train_feat_dyn_array)\n",
    "            # dynamic_real_test_l.append(test_feat_dyn_array)\n",
    "            start_l.append(df[date_col].min())\n",
    "            train_target_l.append(train_ts)\n",
    "            test_target_l.append(test_ts)\n",
    "            stat_cat_l.append(\n",
    "                np.squeeze(df.loc[:, feat_static_cat].drop_duplicates().values)\n",
    "            )\n",
    "    stat_cat_cardinalities = [len(full_df[col].unique()) for col in feat_static_cat]\n",
    "\n",
    "    with open(dataset_path / \"metadata.json\", \"w\") as f:\n",
    "        f.write(\n",
    "            json.dumps(\n",
    "                metadata(\n",
    "                    cardinality=stat_cat_cardinalities,\n",
    "                    freq=\"1D\",\n",
    "                    prediction_length=single_prediction_length,\n",
    "                )\n",
    "            )\n",
    "        )\n",
    "\n",
    "    train_file = dataset_path / \"train\" / \"data.json\"\n",
    "    test_file = dataset_path / \"test\" / \"data.json\"\n",
    "    train_ds = [\n",
    "        {\n",
    "            FieldName.ITEM_ID: \"|\".join(map(str, uniq_comb)),\n",
    "            FieldName.TARGET: target.tolist(),\n",
    "            FieldName.START: str(start),\n",
    "            FieldName.FEAT_STATIC_CAT: fsc.tolist(),\n",
    "            # FieldName.FEAT_DYNAMIC_REAL: fdr.tolist(),\n",
    "        }\n",
    "        for uniq_comb, target, start, fsc in zip(\n",
    "            uniq_combs,\n",
    "            train_target_l,\n",
    "            start_l,\n",
    "            # dynamic_real_train_l,\n",
    "            stat_cat_l,\n",
    "        )\n",
    "    ]\n",
    "    test_ds = [\n",
    "        {\n",
    "            FieldName.ITEM_ID: \"|\".join(map(str, uniq_comb)),\n",
    "            FieldName.TARGET: target.tolist(),\n",
    "            FieldName.START: str(start),\n",
    "            FieldName.FEAT_STATIC_CAT: fsc.tolist(),\n",
    "            # FieldName.FEAT_DYNAMIC_REAL: fdr.tolist(),\n",
    "        }\n",
    "        for uniq_comb, target, start, fsc in zip(\n",
    "            uniq_combs,\n",
    "            test_target_l,\n",
    "            start_l,\n",
    "            # dynamic_real_test_l,\n",
    "            stat_cat_l,\n",
    "        )\n",
    "    ]\n",
    "\n",
    "\n",
    "dataset_recipes = OrderedDict(\n",
    "    {\n",
    "        # each recipe generates a dataset given a path\n",
    "        \"retail_dataset\": partial(generate_retail_dataset, split=\"2011-11-01\")\n",
    "    }\n",
    ")\n",
    "\n",
    "\n",
    "def materialize_dataset(\n",
    "    dataset_name: str,\n",
    "    path: Path = 'default_dataset_path',\n",
    "    regenerate: bool = False,\n",
    ") -> Path:\n",
    "    \"\"\"\n",
    "    Ensures that the dataset is materialized under the `path / dataset_name`\n",
    "    path.\n",
    "    Parameters\n",
    "    ----------\n",
    "    dataset_name\n",
    "        name of the dataset, for instance \"m4_hourly\"\n",
    "    regenerate\n",
    "        whether to regenerate the dataset even if a local file is present.\n",
    "        If this flag is False and the file is present, the dataset will not\n",
    "        be downloaded again.\n",
    "    path\n",
    "        where the dataset should be saved\n",
    "    Returns\n",
    "    -------\n",
    "        the path where the dataset is materialized\n",
    "    \"\"\"\n",
    "\n",
    "    path.mkdir(parents=True, exist_ok=True)\n",
    "    dataset_path = path / dataset_name\n",
    "\n",
    "    dataset_recipe = dataset_recipes[dataset_name]\n",
    "\n",
    "    if not dataset_path.exists() or regenerate:\n",
    "        logging.info(f\"downloading and processing {dataset_name}\")\n",
    "        dataset_recipe(dataset_path=dataset_path)\n",
    "    else:\n",
    "        logging.info(f\"using dataset already processed in path {dataset_path}.\")\n",
    "\n",
    "    return dataset_path\n",
    "\n",
    "\n",
    "def get_dataset(\n",
    "    dataset_name: str,\n",
    "    path: Optional[Path] = None,\n",
    "    regenerate: bool = False,\n",
    ") -> TrainDatasets:\n",
    "    \"\"\"\n",
    "    Get the repository dataset.\n",
    "    Currently only [Retail Dataset](https://archive.ics.uci.edu/ml/datasets/online+retail) is available\n",
    "    Parameters:\n",
    "        dataset_name:\n",
    "            name of the dataset, for instance \"retail\"\n",
    "        regenerate:\n",
    "            whether to regenerate the dataset even if a local file is present.\n",
    "            If this flag is False and the file is present, the dataset will not\n",
    "            be downloaded again.\n",
    "        path:\n",
    "            where the dataset should be saved\n",
    "    Returns:\n",
    "        dataset obtained by either downloading or reloading from local file.\n",
    "    \"\"\"\n",
    "    if path is None:\n",
    "        path = 'sdsd'\n",
    "    dataset_path = materialize_dataset(dataset_name, path, regenerate)\n",
    "\n",
    "    return load_datasets(\n",
    "        metadata=dataset_path,\n",
    "        train=dataset_path / \"train\",\n",
    "        test=dataset_path / \"test\",)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/compat/_optional.py:132\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 132\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[0;32m~/.python/current/lib/python3.10/importlib/__init__.py:126\u001b[0m, in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m    125\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 126\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1050\u001b[0m, in \u001b[0;36m_gcd_import\u001b[0;34m(name, package, level)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1027\u001b[0m, in \u001b[0;36m_find_and_load\u001b[0;34m(name, import_)\u001b[0m\n",
      "File \u001b[0;32m<frozen importlib._bootstrap>:1004\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[0;34m(name, import_)\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'openpyxl'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m retail_dataset_url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m20Retail.xlsx\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 2\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_excel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mretail_dataset_url\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m combination \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStockCode\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCountry\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m      4\u001b[0m df \u001b[38;5;241m=\u001b[39m _preprocess_retail_data(df, combination)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/excel/_base.py:504\u001b[0m, in \u001b[0;36mread_excel\u001b[0;34m(io, sheet_name, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, date_format, thousands, decimal, comment, skipfooter, storage_options, dtype_backend, engine_kwargs)\u001b[0m\n\u001b[1;32m    502\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(io, ExcelFile):\n\u001b[1;32m    503\u001b[0m     should_close \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 504\u001b[0m     io \u001b[38;5;241m=\u001b[39m \u001b[43mExcelFile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    505\u001b[0m \u001b[43m        \u001b[49m\u001b[43mio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    506\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    507\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    508\u001b[0m \u001b[43m        \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    509\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;129;01mand\u001b[39;00m engine \u001b[38;5;241m!=\u001b[39m io\u001b[38;5;241m.\u001b[39mengine:\n\u001b[1;32m    511\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    512\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEngine should not be specified when passing \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124man ExcelFile - ExcelFile already has the engine set\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    514\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/excel/_base.py:1580\u001b[0m, in \u001b[0;36mExcelFile.__init__\u001b[0;34m(self, path_or_buffer, engine, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m   1577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine \u001b[38;5;241m=\u001b[39m engine\n\u001b[1;32m   1578\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options \u001b[38;5;241m=\u001b[39m storage_options\n\u001b[0;32m-> 1580\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engines\u001b[49m\u001b[43m[\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1581\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_io\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1582\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m    \u001b[49m\u001b[43mengine_kwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mengine_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/io/excel/_openpyxl.py:552\u001b[0m, in \u001b[0;36mOpenpyxlReader.__init__\u001b[0;34m(self, filepath_or_buffer, storage_options, engine_kwargs)\u001b[0m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;129m@doc\u001b[39m(storage_options\u001b[38;5;241m=\u001b[39m_shared_docs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstorage_options\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    535\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    536\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    539\u001b[0m     engine_kwargs: \u001b[38;5;28mdict\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    540\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    541\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;124;03m    Reader using openpyxl engine.\u001b[39;00m\n\u001b[1;32m    543\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;124;03m        Arbitrary keyword arguments passed to excel engine.\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 552\u001b[0m     \u001b[43mimport_optional_dependency\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mopenpyxl\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m    554\u001b[0m         filepath_or_buffer,\n\u001b[1;32m    555\u001b[0m         storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[1;32m    556\u001b[0m         engine_kwargs\u001b[38;5;241m=\u001b[39mengine_kwargs,\n\u001b[1;32m    557\u001b[0m     )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/compat/_optional.py:135\u001b[0m, in \u001b[0;36mimport_optional_dependency\u001b[0;34m(name, extra, errors, min_version)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 135\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;66;03m# Handle submodules: if we have submodule, grab parent module from sys.modules\u001b[39;00m\n",
      "\u001b[0;31mImportError\u001b[0m: Missing optional dependency 'openpyxl'.  Use pip or conda to install openpyxl."
     ]
    }
   ],
   "source": [
    "retail_dataset_url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online%20Retail.xlsx\"\n",
    "df = pd.read_excel(retail_dataset_url)\n",
    "combination = [\"StockCode\", \"Country\"]\n",
    "df = _preprocess_retail_data(df, combination)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
